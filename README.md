# Machine Learning Classification Methods

## Project Overview
This assignment aims to enhance understanding of key machine learning classification algorithms, including:
- **K-Nearest Neighbors (KNN)**
- **Logistic Regression**
- **Support Vector Machines (SVM) with different kernels**
- **Ensemble Methods (Boosting and Bagging)**

Through experimentation and evaluation, we will analyze how different configurations affect model performance using classification metrics.

## Dataset
We used the **Breast Cancer dataset** to apply diagnosis and evaluate classification models. Other publicly available datasets can also be used, such as:
- **Iris dataset**
- **Any other binary or multi-class classification dataset**

The dataset should contain at least two classes to allow proper classification analysis.

## Tools and Libraries
- **Python**
- **NumPy & Pandas** (for data manipulation)
- **Scikit-learn** (for model implementation and evaluation)
- **Matplotlib & Seaborn** (for visualization)

## Evaluation Metrics
To assess model performance, the following metrics will be used:
- **Accuracy**
- **Precision**
- **Recall**
- **F1-score**
- **ROC-AUC**

---
## Assignment Tasks

### **Part 1: K-Nearest Neighbors (KNN)**
1. Implement the **KNN algorithm** using APIs.
2. Experiment with **three different distance metrics**:
   - Euclidean Distance
   - Manhattan Distance
   - Cosine Distance
3. Use **cross-validation** to determine the optimal value of **K**.
4. Analyze the results:
   - How do different distance metrics impact classification performance?
   - What is the best value of K for the dataset, and why?

### **Part 2: Logistic Regression**
1. Train a **Logistic Regression** model.
2. Apply **regularization techniques** (L1 & L2).
3. Evaluate performance using classification metrics.
4. Compare **Logistic Regression vs. KNN** in terms of performance.

### **Part 3: Support Vector Machines (SVM)**
1. Implement and train an **SVM model**.
2. Experiment with **three different kernels**:
   - Linear Kernel
   - Polynomial Kernel
   - Radial Basis Function (RBF) Kernel
3. Compare the performance of different kernels using classification metrics.
4. Discuss:
   - How does the choice of kernel affect model accuracy and other metrics?

### **Part 4: Ensemble Methods**
1. **Boosting:** Train a model using **AdaBoost**.
2. **Bagging:** Train a model using **Bagging** or **Random Forest**.
3. Compare the performance of **Boosting vs. Bagging**.
4. Discussion:
   - Which ensemble method performed better and why?
   - How do ensemble methods compare to individual models (KNN, Logistic Regression, SVM)?

---
## Conclusion
This project will provide a comparative study of different classification algorithms, helping us understand their strengths, weaknesses, and appropriate use cases. The results will be documented with **performance metrics and visualizations** to support the analysis.

## Authors
This project is completed by:
- Ali Shaikh Qasem.
- Abdelrahman Jaber.

